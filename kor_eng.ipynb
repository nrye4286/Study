{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"O2tdKKrcN6pi"},"outputs":[],"source":["#배치처리 시 시퀀스 길이가 다를때 어떻게 해야하는지\n","#디코더의 인풋으로는 정확히 무엇을 넣어야 하고\n","#아웃풋과 어떻게 loss계산을 해야하는지\n","#배치속에서 시퀀스 길이가 다를 때 추가적인 마스크를 써주어야 하는데 어떤 모양이여야 하는지\n","#패딩은 예측해야 하는지(손실값 계산)\n","#예측 안 한다면 손실값에 관여 안하도록 어떻게 해야할지"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Si7z-xY1PYOK"},"outputs":[],"source":["#하고있던거: 0, 1, 2(eos), 3(sos) 맞춤으로 된 트랜스포머 구조 바꾸기"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16730,"status":"ok","timestamp":1719375909543,"user":{"displayName":"이지민","userId":"17530294469746342616"},"user_tz":-540},"id":"VORoZZIhzrNz","outputId":"9d1da7ff-8ada-4428-8b97-861d60b31f2b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1719375909543,"user":{"displayName":"이지민","userId":"17530294469746342616"},"user_tz":-540},"id":"OVA9VLQp09pj"},"outputs":[],"source":["import pandas as pd\n","from glob import glob"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":704,"status":"ok","timestamp":1719375910245,"user":{"displayName":"이지민","userId":"17530294469746342616"},"user_tz":-540},"id":"vCu1yUlq1FPg"},"outputs":[],"source":["data = glob('/content/drive/MyDrive/kor-eng/한국어-영어 번역(병렬) 말뭉치/*.xlsx')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1719375910245,"user":{"displayName":"이지민","userId":"17530294469746342616"},"user_tz":-540},"id":"FFj2LB49dHdu","outputId":"d9e8546a-4d32-4c13-f5fb-6fb18a2b6fb6"},"outputs":[{"data":{"text/plain":["['/content/drive/MyDrive/kor-eng/한국어-영어 번역(병렬) 말뭉치/1_구어체(2).xlsx',\n"," '/content/drive/MyDrive/kor-eng/한국어-영어 번역(병렬) 말뭉치/2_대화체.xlsx',\n"," '/content/drive/MyDrive/kor-eng/한국어-영어 번역(병렬) 말뭉치/5_문어체_조례.xlsx',\n"," '/content/drive/MyDrive/kor-eng/한국어-영어 번역(병렬) 말뭉치/1_구어체(1).xlsx',\n"," '/content/drive/MyDrive/kor-eng/한국어-영어 번역(병렬) 말뭉치/4_문어체_한국문화.xlsx',\n"," '/content/drive/MyDrive/kor-eng/한국어-영어 번역(병렬) 말뭉치/6_문어체_지자체웹사이트.xlsx',\n"," '/content/drive/MyDrive/kor-eng/한국어-영어 번역(병렬) 말뭉치/3_문어체_뉴스(2).xlsx',\n"," '/content/drive/MyDrive/kor-eng/한국어-영어 번역(병렬) 말뭉치/3_문어체_뉴스(4).xlsx',\n"," '/content/drive/MyDrive/kor-eng/한국어-영어 번역(병렬) 말뭉치/3_문어체_뉴스(3).xlsx',\n"," '/content/drive/MyDrive/kor-eng/한국어-영어 번역(병렬) 말뭉치/3_문어체_뉴스(1).xlsx']"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"IWnXxPyQdUsj"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/openpyxl/styles/stylesheet.py:241: UserWarning: Workbook contains no default style, apply openpyxl's default\n","  warn(\"Workbook contains no default style, apply openpyxl's default\")\n","/usr/local/lib/python3.10/dist-packages/openpyxl/styles/stylesheet.py:241: UserWarning: Workbook contains no default style, apply openpyxl's default\n","  warn(\"Workbook contains no default style, apply openpyxl's default\")\n","/usr/local/lib/python3.10/dist-packages/openpyxl/styles/stylesheet.py:241: UserWarning: Workbook contains no default style, apply openpyxl's default\n","  warn(\"Workbook contains no default style, apply openpyxl's default\")\n","/usr/local/lib/python3.10/dist-packages/openpyxl/styles/stylesheet.py:241: UserWarning: Workbook contains no default style, apply openpyxl's default\n","  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"]}],"source":["df = pd.DataFrame(columns = ['원문','번역문'])\n","path = '/content/drive/MyDrive/kor-eng/한국어-영어 번역(병렬) 말뭉치/'\n","\n","file_list = [ '1_구어체(2).xlsx',\n"," '2_대화체.xlsx',\n"," '5_문어체_조례.xlsx',\n"," '1_구어체(1).xlsx',\n"," '4_문어체_한국문화.xlsx',\n"," '6_문어체_지자체웹사이트.xlsx',\n"," '3_문어체_뉴스(4).xlsx',\n"," '3_문어체_뉴스(3).xlsx',\n"," '3_문어체_뉴스(2).xlsx',\n"," '3_문어체_뉴스(1).xlsx']\n","\n","for data in file_list:\n","    temp = pd.read_excel(path+data)\n","    df = pd.concat([df,temp[['원문','번역문']]])"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"cczZlqw7hwoW"},"outputs":[],"source":["!pip install konlpy"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"1PHoeJi8juqO"},"outputs":[],"source":["!pip install nltk"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"WCgj0DIQhx6j"},"outputs":[],"source":["from konlpy.tag import Okt\n","import nltk\n","nltk.download('popular')\n","from nltk.tokenize import word_tokenize"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r5Cu-6JrdLRF"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","import random\n","import math\n","from sklearn.preprocessing import LabelEncoder\n","kor_encoder = LabelEncoder()\n","eng_encoder = LabelEncoder()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R1d7l0bdeD8l"},"outputs":[],"source":["a = df.to_numpy()\n","a.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1716342356200,"user":{"displayName":"이지민","userId":"17530294469746342616"},"user_tz":-540},"id":"YKquGPScMRnS","outputId":"1acc1d4e-83c7-419e-b878-f5f0749ffa29"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nidx = np.arange(a.shape[0])\\nnp.random.shuffle(idx)\\n\\n\\na = a[idx]\\n'"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"\n","idx = np.arange(a.shape[0])\n","np.random.shuffle(idx)\n","\n","\n","a = a[idx]\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gP8tmSi4iot3"},"outputs":[],"source":["print(a[3,0])\n","print(a[3,1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PieoJWEwihxw"},"outputs":[],"source":["tokenizer = Okt()\n","print(tokenizer.morphs(a[0,0]))"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"n2TgDULDjgNW"},"outputs":[],"source":["word_tokenize(a[0,1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xs7Gd1yIKl-T"},"outputs":[],"source":["kor = []\n","eng = []\n","for i in range(150000):\n","  kor.append(tokenizer.morphs(a[i,0]))\n","for i in range(150000):\n","  eng.append(word_tokenize(a[i,1]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o-a4Xo_TLMYl"},"outputs":[],"source":["print(len(kor))\n","print(len(eng))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UTan1o6kAcmQ"},"outputs":[],"source":["kor[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kmJEmcdVLhbr"},"outputs":[],"source":["#토큰화-\u003e배치처리('[PAD]'처리등과 함께)  (배열속 넘파이의 구조)   -\u003e       (텐서 변환 후) (학습 함수 안에서)라벨인코딩   -\u003e loss계산할때 원-핫 변환"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6j65HT7uWmSg"},"outputs":[],"source":["kor_unq = ['[PAD]','[SOS]','[EOS]']\n","for i in range(150000):\n","  for j in range(len(kor[i])):\n","    if kor[i][j] not in kor_unq:\n","      kor_unq.append(kor[i][j])\n","kor_unq = np.array(kor_unq)\n","kor_encoder.fit(kor_unq)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WNLKcVACLIY2"},"outputs":[],"source":["eng_unq = ['[PAD]','[SOS]','[EOS]']\n","for i in range(150000):\n","  for j in range(len(eng[i])):\n","    if eng[i][j] not in eng_unq:\n","      eng_unq.append(eng[i][j])\n","eng_unq = np.array(eng_unq)\n","eng_encoder.fit(eng_unq)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CmzGD-81NiF-"},"outputs":[],"source":["kor_token_len = len(kor_encoder.classes_)\n","eng_token_len = len(eng_encoder.classes_)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g64pIk-Al7BA"},"outputs":[],"source":["eng_token_len"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t_QBfOeaj1D0"},"outputs":[],"source":["pad_index = eng_encoder.transform(['[PAD]'])[0]\n","sos_index = eng_encoder.transform(['[SOS]'])[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nDkl7WtAxMRh"},"outputs":[],"source":["pad_index \u003c sos_index"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MGsSO4XYifwx"},"outputs":[],"source":["transformer_model = nn.Transformer(nhead=16, num_encoder_layers=12, batch_first=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1716342902027,"user":{"displayName":"이지민","userId":"17530294469746342616"},"user_tz":-540},"id":"1fdkEw0VirhS","outputId":"2f484a40-2d71-411e-f5b0-95248e9a3def"},"outputs":[{"data":{"text/plain":["torch.Size([32, 1, 512])"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["src = torch.rand((32, 32, 512))\n","tgt = torch.rand((32, 1, 512))\n","out = transformer_model(src, tgt)\n","out.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vGtHfhX0kIcn"},"outputs":[],"source":["class PositionalEncoding(nn.Module):\n","    def __init__(self, dim_model, dropout_p, max_len):\n","        super().__init__()\n","        self.dropout = nn.Dropout(dropout_p)\n","\n","        pos_encoding = torch.zeros(max_len, dim_model)\n","        positions_list = torch.arange(0, max_len, dtype=torch.float).view(-1, 1)\n","        division_term = torch.exp(torch.arange(0, dim_model, 2).float() * (-math.log(10000.0)) / dim_model)\n","\n","        pos_encoding[:, 0::2] = torch.sin(positions_list * division_term)\n","        pos_encoding[:, 1::2] = torch.cos(positions_list * division_term)\n","\n","        pos_encoding = pos_encoding.unsqueeze(0).transpose(0, 1)\n","        self.register_buffer(\"pos_encoding\",pos_encoding)\n","\n","    def forward(self, token_embedding: torch.tensor) -\u003e torch.tensor:\n","        return self.dropout(token_embedding + self.pos_encoding[:token_embedding.size(0), :])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1716342902558,"user":{"displayName":"이지민","userId":"17530294469746342616"},"user_tz":-540},"id":"dwDYUq0uTTdC","outputId":"57c10c6f-48a8-4307-856f-565bb161d76e"},"outputs":[{"data":{"text/plain":["torch.Size([10, 100])"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["hi = nn.Embedding(100, 100)\n","hihi = hi(torch.tensor([1,2,3,4,5,6,7,8,9,10]))\n","hihi.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1716342902558,"user":{"displayName":"이지민","userId":"17530294469746342616"},"user_tz":-540},"id":"1-3bPkSOTpLJ","outputId":"c1da4516-9d7e-4b6c-de91-91e522b9fad3"},"outputs":[{"data":{"text/plain":["16.0"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["math.sqrt(256)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pALUSPBMkDKa"},"outputs":[],"source":["class Transformer(nn.Module):\n","    def __init__( self, kor_token_len, eng_token_len, dim_model, num_heads, num_encoder_layers, num_decoder_layers, dropout_p, ):\n","        super().__init__()\n","        self.dim_model = dim_model\n","        self.positional_encoder = PositionalEncoding(dim_model=dim_model, dropout_p=dropout_p, max_len=5000)\n","        self.kor_embedding = nn.Embedding(kor_token_len, dim_model)\n","        self.eng_embedding = nn.Embedding(eng_token_len, dim_model)\n","        self.transformer = nn.Transformer(\n","            batch_first=True,\n","            d_model=dim_model,\n","            nhead=num_heads,\n","            num_encoder_layers=num_encoder_layers,\n","            num_decoder_layers=num_decoder_layers,\n","            dropout=dropout_p,\n","        )\n","        self.out = nn.Linear(dim_model, eng_token_len-2)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, src, tgt, tgt_mask=None, src_pad_mask=None, tgt_pad_mask=None):\n","        src = self.kor_embedding(src) * math.sqrt(self.dim_model)\n","        tgt = self.eng_embedding(tgt) * math.sqrt(self.dim_model)\n","        src = self.positional_encoder(src)\n","        tgt = self.positional_encoder(tgt)\n","\n","        transformer_out = self.transformer(src, tgt, tgt_mask=tgt_mask, src_key_padding_mask=src_pad_mask, tgt_key_padding_mask=tgt_pad_mask)\n","        out = self.sigmoid(self.out(transformer_out))\n","        return out\n","\n","    def get_tgt_mask(self, size) -\u003e torch.tensor:\n","        mask = torch.tril(torch.ones(size, size) == 1)\n","        mask = mask.float()\n","        mask = mask.masked_fill(mask == 0, float('-inf'))\n","        mask = mask.masked_fill(mask == 1, float(0.0))\n","\n","        return mask\n","\n","    def create_pad_mask(self, matrix: torch.tensor) -\u003e torch.tensor:\n","        return (matrix == '[PAD]' or matrix == '[EOS]')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wmUZr5chmYBt"},"outputs":[],"source":["def batchify_data(data, batch_size=16, padding=False):\n","    batches = []\n","    for idx in range(0, len(data), batch_size):\n","        if idx + batch_size \u003c len(data):\n","            if padding:\n","                max_batch_length = 0\n","                for seq in data[idx : idx + batch_size]:\n","                    if len(seq) \u003e max_batch_length:\n","                        max_batch_length = len(seq)\n","                for seq_idx in range(batch_size):\n","                    remaining_length = max_batch_length - len(data[idx + seq_idx])\n","                    data[idx + seq_idx] = ['[SOS]'] + data[idx + seq_idx] + ['[EOS]']\n","                    data[idx + seq_idx] += ['[PAD]'] * remaining_length\n","\n","            batches.append(np.array(data[idx : idx + batch_size]))\n","\n","    print(f\"{len(batches)} batches of size {batch_size}\")\n","\n","    return batches"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QtmW3YR9mbCc"},"outputs":[],"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","model = Transformer(kor_token_len=kor_token_len, eng_token_len = eng_token_len, dim_model=256, num_heads=4, num_encoder_layers=6, num_decoder_layers=6, dropout_p=0.1).to(device)\n","opt = torch.optim.SGD(model.parameters(), lr=0.000001)\n","loss_fn = nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Zanj5QICdsN"},"outputs":[],"source":["\n","model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/model.pt'))\n","opt.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/opt.pt'))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ydvCy92wmcaU"},"outputs":[],"source":["def onehot(y, eng_token_len):\n","  a = []\n","  for i in range(y.shape[0]):\n","    b = []\n","    for j in range(y[i].shape[0]):\n","      c = [0] * eng_token_len\n","      c[y[i,j]] = 1\n","      b.append(c)\n","    a.append(b)\n","  a = torch.tensor(a, dtype=torch.float16)\n","  return a.to(device)\n","\n","def train_loop(model, opt, loss_fn, kor_dataloader, eng_dataloader):\n","    model.train()\n","    total_loss = 0\n","\n","    for i in range(len(kor_dataloader)):\n","        if i%50 == 0:\n","          print(i)\n","        X, y = kor_dataloader[i].copy(), eng_dataloader[i].copy()\n","        for j in range(len(X)):\n","          X[j] = kor_encoder.transform(X[j])\n","          y[j] = eng_encoder.transform(y[j])\n","        X = X.astype(np.int32)\n","        y = y.astype(np.int32)\n","        X, y = torch.tensor(X, dtype=torch.long, device=device), torch.tensor(y, dtype=torch.long, device=device)\n","\n","        y_input = y[:,:-1]\n","        y_expected = y[:,1:]\n","        sequence_length = y_input.size(1)\n","        tgt_mask = model.get_tgt_mask(sequence_length).to(device)\n","\n","        pred = model(X, y_input, tgt_mask)\n","        y_expected = onehot(y_expected, eng_token_len)\n","        y_expected = torch.cat([y_expected[:,:,:pad_index], y_expected[:,:,pad_index+1:]],dim=2)\n","        loss = loss_fn(pred, y_expected)\n","\n","        opt.zero_grad()\n","        loss.backward()\n","        opt.step()\n","\n","        total_loss += loss.detach().item()\n","\n","    return total_loss / len(kor_dataloader)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bqkX7X8RmdgM"},"outputs":[],"source":["def validation_loop(model, loss_fn, kor_dataloader, eng_dataloader):\n","    model.eval()\n","    total_loss = 0\n","\n","    with torch.no_grad():\n","        for i in range(len(kor_dataloader)):\n","            X, y = kor_dataloader[i].copy(), eng_dataloader[i].copy()\n","            for j in range(len(X)):\n","              X[j].shape\n","              X[j] = kor_encoder.transform(X[j])\n","              y[j] = eng_encoder.transform(y[j])\n","            X = X.astype(np.int32)\n","            y = y.astype(np.int32)\n","            X, y = torch.tensor(X, dtype=torch.long, device=device), torch.tensor(y, dtype=torch.long, device=device)\n","\n","\n","            y_input = y[:,:-1]\n","            y_expected = y[:,1:]\n","\n","            sequence_length = y_input.size(1)\n","            tgt_mask = model.get_tgt_mask(sequence_length).to(device)\n","\n","            pred = model(X, y_input, tgt_mask)\n","\n","            y_expected = onehot(y_expected, eng_token_len)\n","            y_expected = torch.cat([y_expected[:,:,:pad_index], y_expected[:,:,pad_index+1:]],dim=2)\n","            loss = loss_fn(pred, y_expected)\n","            total_loss += loss.detach().item()\n","\n","    return total_loss / len(kor_dataloader)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"chFMLa4bmezJ"},"outputs":[],"source":["def fit(model, opt, loss_fn, epochs, kor_train_dataloader, eng_train_dataloader, kor_test_dataloader=0, eng_test_dataloader=0):\n","    train_loss_list, validation_loss_list = [], []\n","    min_loss = 10000\n","    print(\"Training and validating model\")\n","    for epoch in range(epochs):\n","        print(\"-\"*25, f\"Epoch {epoch + 1}\",\"-\"*25)\n","\n","        train_loss = train_loop(model, opt, loss_fn, kor_train_dataloader, eng_train_dataloader)\n","        train_loss_list += [train_loss]\n","\n","        #validation_loss = validation_loop(model, loss_fn, kor_test_dataloader, eng_test_dataloader)\n","        #validation_loss_list += [validation_loss]\n","\n","        print(f\"Training loss: {train_loss:.4f}\")\n","        #print(f\"Validation loss: {validation_loss:.4f}\")\n","        print()\n","        torch.save(model.state_dict(), '/content/drive/MyDrive/Colab Notebooks/model.pt')\n","        torch.save(opt.state_dict(), '/content/drive/MyDrive/Colab Notebooks/opt.pt')\n","\n","\n","    return train_loss_list, validation_loss_list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"134lddjlmhP1"},"outputs":[],"source":["def predict(model, input_sequence, max_length=15, SOS_token='[SOS]', EOS_token='[EOS]'):\n","    model.eval()\n","    save = input_sequence.copy()\n","    input_sequence[0] = kor_encoder.transform(input_sequence[0])\n","    input_sequence = input_sequence.astype(np.int32)\n","    X = torch.tensor(input_sequence, dtype=torch.long, device=device)\n","\n","    y_input = eng_encoder.transform([SOS_token])\n","    y_input = y_input.astype(np.int32)\n","    y_input = torch.tensor(y_input, dtype=torch.long, device=device).reshape(1,1)\n","\n","    for _ in range(max_length):\n","        tgt_mask = model.get_tgt_mask(y_input.size(1)).to(device)\n","\n","        pred = model(X, y_input, tgt_mask)\n","        pred = pred.topk(1)[1].view(-1)[-1].item()\n","        if pred \u003e eng_encoder.transform(['[PAD]'])[0]:\n","          pred = pred+1\n","        next_item = torch.tensor([[pred]], device=device)\n","\n","        y_input = torch.cat((y_input, next_item), dim=1)\n","\n","        if next_item.view(-1).item() == eng_encoder.transform(['[EOS]']):\n","          break\n","    print('------------------------------------------------------------------------------------')\n","    for i in range(save.shape[1]):\n","      print(save[0,i], end=\" \")\n","    print()\n","    for i in range(y_input.shape[1]):\n","      print(eng_encoder.inverse_transform(y_input[0,i:i+1].cpu().numpy())[0], end=\" \")\n","    print()\n","    print('-----------------------------------------------------------------------------------')\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IMF-pPK1_vld","outputId":"763d28b2-6874-41ee-91f2-d4a80e83ad2f"},"outputs":[{"name":"stdout","output_type":"stream","text":["-------------------- 1 -----------------------\n","-------------------- 0 -----------------------\n","468 batches of size 64\n","468 batches of size 64\n","Training and validating model\n","------------------------- Epoch 1 -------------------------\n","0\n"]}],"source":["for j in range(1,10):\n","  print('--------------------',j,'-----------------------')\n","  idx = list(range(150000))\n","  random.shuffle(idx)\n","  kkor = []\n","  eeng = []\n","  for i in range(150000):\n","      kkor.append(kor[idx[i]])\n","      eeng.append(eng[idx[i]])\n","  kor = kkor\n","  eng = eeng\n","  for i in range(5):\n","    print('--------------------',i,'-----------------------')\n","    kor_train_dataloader = batchify_data(kor[i*30000:(i+1)*30000], batch_size=64, padding=True)\n","    eng_train_dataloader = batchify_data(eng[i*30000:(i+1)*30000], batch_size=64, padding=True)\n","    train_loss_list, validation_loss_list = fit(model, opt, loss_fn, 1, kor_train_dataloader, eng_train_dataloader)\n","    for i in range(5):\n","      predict(model,kor_train_dataloader[0][i:i+1].copy(), max_length=30)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R1zZXQZra6k8"},"outputs":[],"source":["torch.save(model.state_dict(), '/content/drive/MyDrive/Colab Notebooks/model.pt')\n","torch.save(opt.state_dict(), '/content/drive/MyDrive/Colab Notebooks/opt.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19622,"status":"ok","timestamp":1716353975709,"user":{"displayName":"이지민","userId":"17530294469746342616"},"user_tz":-540},"id":"56C0nI3Ta_t_","outputId":"8bc73321-1ad6-4f48-ffd9-2eae85fc32ac"},"outputs":[{"name":"stdout","output_type":"stream","text":["------------------------------------------------------------------------------------\n","[SOS] 저번 내한 때 는 콘서트 의 촬영 이 가능했었는데 , 올해 에는 촬영 이 불가능한가요 ? [EOS] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n","[SOS] Kepco brochure Kepco Assassination brochure brochure brochure brochure brochure brochure brochure brochure brochure brochure brochure Aboriginal brochure Aboriginal brochure Aboriginal brochure Aboriginal brochure Aboriginal brochure Aboriginal brochure Aboriginal brochure Aboriginal \n","-----------------------------------------------------------------------------------\n","------------------------------------------------------------------------------------\n","[SOS] 만약 그 들 이 내 공연 을 본다면 내 재능 에 놀랄 거야 . [EOS] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n","[SOS] trickled trickled braveness FutureNet cultivate braveness aspirin cultivate braveness aspirin cultivate braveness cultivate braveness braveness cultivate cultivate braveness braveness cultivate cultivate braveness braveness braveness cultivate cultivate braveness braveness braveness braveness \n","-----------------------------------------------------------------------------------\n","------------------------------------------------------------------------------------\n","[SOS] 500엔 을 더 내면 원하시는 좌석 에 앉으실 수 있으세요 . [EOS] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n","[SOS] Kepco lagoon braveness lagoon braveness lagoon braveness lagoon braveness Motion braveness lagoon braveness Motion braveness NBR integrity lagoon Motion NBR integrity lagoon Motion NBR lagoon Motion NBR lagoon Motion NBR \n","-----------------------------------------------------------------------------------\n","------------------------------------------------------------------------------------\n","[SOS] 이 배 에는 수영장 이 세 개 에 테니스장 , 배구 장도 있어요 . [EOS] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n","[SOS] Kepco Kepco Kepco Kepco brochure Kepco brochure Kepco brochure Kepco brochure Kepco brochure Kepco brochure Kepco brochure Kepco brochure Kepco brochure Kepco brochure Kepco brochure Kepco brochure Kepco brochure Kepco \n","-----------------------------------------------------------------------------------\n","------------------------------------------------------------------------------------\n","[SOS] 당신 이 요청 하신 리스트 는 아래 와 같습니다 . [EOS] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n","[SOS] aspirin aspirin braveness protype protype braveness aspirin braveness aspirin braveness aspirin braveness aspirin braveness protype protype protype braveness aspirin braveness aspirin braveness aspirin braveness aspirin braveness protype protype protype braveness \n","-----------------------------------------------------------------------------------\n"]}],"source":["for i in range(5):\n","  predict(model,kor_train_dataloader[2][i:i+1].copy(), max_length=30)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOi9Gvmza1g8Jb97WJPGohM","gpuType":"L4","machine_shape":"hm","mount_file_id":"1sr641NdSOF5m8wuZz9WUkxZT9xwKCSjX","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}